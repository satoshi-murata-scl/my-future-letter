import { NextResponse } from "next/server";
import OpenAI from "openai";

// ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆVercel ã®æœ€å¤§å€¤ 20ç§’ï¼‰
const TIMEOUT = 19000; // 19ç§’ï¼ˆ20ç§’ã‚’è¶…ãˆã‚‹ã¨ Vercel å´ã§å¼·åˆ¶çµ‚äº†ã•ã‚Œã‚‹ï¼‰

export async function POST(req) {
  console.log("ğŸ“© API ã« POST ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå±Šãã¾ã—ãŸï¼");

  try {
    const { currentSituation, futureGoals } = await req.json();
    console.log("ğŸ” å—ã‘å–ã£ãŸãƒ‡ãƒ¼ã‚¿:", { currentSituation, futureGoals });

    if (!currentSituation || !futureGoals) {
      console.error("âŒ å…¥åŠ›ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼");
      return NextResponse.json({ message: "ã—ã£ã‹ã‚Šã¨ãªã‚ŠãŸã„è‡ªåˆ†ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚" }, { status: 400 });
    }

    console.log("ğŸš€ OpenAI API ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...");

    const openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
      timeout: TIMEOUT, // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ 19ç§’ ã«è¨­å®š
    });

    const response = await openai.chat.completions.create({
      model: "gpt-4",
      messages: [
        { role: "system", content: "ã‚ãªãŸã¯æœªæ¥ã®è‡ªåˆ†ã¨ã—ã¦åŠ±ã¾ã—ã®æ‰‹ç´™ã‚’æ›¸ãAIã§ã™ã€‚" },
        { role: "user", content: `ç¾åœ¨ã®çŠ¶æ³: ${currentSituation}\næœªæ¥ã®ç›®æ¨™: ${futureGoals}` },
      ],
      max_tokens: 1000, // ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã‚’èª¿æ•´
    });

    console.log("âœ… OpenAI ã‹ã‚‰ã®å¿œç­”:", response);

    if (!response || !response.choices || response.choices.length === 0) {
      console.error("âŒ OpenAI ã®å¿œç­”ãŒç„¡åŠ¹ã§ã™:", response);
      return NextResponse.json({ message: "AIã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚" }, { status: 500 });
    }

    const letter = response.choices[0].message.content.trim();
    return NextResponse.json({ letter }, { status: 200 });

  } catch (error) {
    console.error("âŒ APIã‚¨ãƒ©ãƒ¼:", error);
    return NextResponse.json({ message: "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", error: error.message }, { status: 500 });
  }
}
