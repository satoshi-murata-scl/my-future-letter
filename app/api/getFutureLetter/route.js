import { NextResponse } from "next/server";
import OpenAI from "openai";

// OpenAI API ã®è¨­å®š
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(req) {
  console.log("ğŸ“© API ã« POST ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå±Šãã¾ã—ãŸï¼");

  try {
    const { currentSituation, futureGoals } = await req.json();
    console.log("ğŸ” å—ã‘å–ã£ãŸãƒ‡ãƒ¼ã‚¿:", { currentSituation, futureGoals });

    if (!currentSituation || !futureGoals) {
      return NextResponse.json({ message: "ã—ã£ã‹ã‚Šã¨ãªã‚ŠãŸã„è‡ªåˆ†ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚" }, { status: 400 });
    }

    console.log("ğŸš€ OpenAI API ã«ã‚¹ãƒˆãƒªãƒ¼ãƒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...");

    const response = await openai.chat.completions.create({
      model: "gpt-4-turbo",
      messages: [
        { role: "system", content: `
          ã‚ãªãŸã¯æœªæ¥ã®è‡ªåˆ†ã¨ã—ã¦åŠ±ã¾ã—ã®æ‰‹ç´™ã‚’æ›¸ãAIã§ã™ã€‚
          - ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãã®ã¾ã¾ä½¿ã‚ãšã€é©åˆ‡ã«è¨€ã„æ›ãˆã¦æ‰‹ç´™ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
          - æ–‡ç« ã¯èª­ã¿ã‚„ã™ãã€æ¸©ã‹ã¿ã®ã‚ã‚‹è¨€è‘‰ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚
          - **æ–‡ç« ã®æ§‹æˆã‚’ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåŒ–ã›ãšã€è‡ªç„¶ãªæ‰‹ç´™ã¨ã—ã¦æ›¸ã„ã¦ãã ã•ã„ã€‚**
          - **æ”¹è¡Œã¨æ®µè½ã”ã¨ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’é©åˆ‡ã«å…¥ã‚Œã¦ãã ã•ã„ã€‚**
          - **ã€Œåƒ•ã€ãªã©ã®ä¸€äººç§°ã‚’ä½¿ã‚ãšã€ã€Œéå»ã®è‡ªåˆ†ã€ã‚„ã€Œå›ã€ã€Œç§ã€ãªã©ã‚’ä½¿ç”¨ã—ã¦æ€§åˆ¥ã«åã‚‰ãªã„è¡¨ç¾ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚**
          - **æ–‡ç« ã®å§‹ã‚ã«æœªæ¥ã®è‡ªåˆ†ã‹ã‚‰ã€éå»ã®è‡ªåˆ†ã«å‘ã‘ã¦æŒ¨æ‹¶ã‚’ã—ã¦ãã ã•ã„ã€‚**
          - **æ–‡ç« ã®æœ€å¾Œã«æœªæ¥ã®è‡ªåˆ†ã‹ã‚‰ã€éå»ã®è‡ªåˆ†ã«å‘ã‘ã¦åŠ±ã¾ã—ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨æœªæ¥ã®è‡ªåˆ†ã‚ˆã‚Šã¨å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚**
          - **æœªæ¥ã®è‡ªåˆ†ã«ãªã‚‹ãŸã‚ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚„ã€ã‚„ã‚‰ãªã‘ã‚Œã°ã„ã‘ãªã„ã“ã¨ã€æ³¨æ„ã™ã‚‹ç‚¹ãªã©ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚**
          - **å°‘ã—ã ã‘ãƒ•ãƒ©ãƒ³ã‚¯ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã§è¦ªã—ã¿ã‚’è¾¼ã‚ã¦ãã ã•ã„ã€‚**
        `},
        { role: "user", content: `
          æœªæ¥ã®è‡ªåˆ†ã‹ã‚‰ä»Šã®è‡ªåˆ†ã¸ã®æ‰‹ç´™ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚
          ç¾åœ¨ã®çŠ¶æ³: ã€Œ${currentSituation}ã€
          æœªæ¥ã®ç›®æ¨™: ã€Œ${futureGoals}ã€
        `},
      ],
      max_tokens: 1000, 
      temperature: 0.7,
      stream: true, // ğŸ”¹ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–
    });

    console.log("âœ… OpenAI ã‹ã‚‰ã®å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­...");

    // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ã‚‹
    const stream = new ReadableStream({
      async start(controller) {
        for await (const chunk of response) {
          const text = chunk.choices[0]?.delta?.content || "";
          controller.enqueue(text);
        }
        controller.close();
      },
    });

    return new Response(stream, {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "no-cache",
      },
    });

  } catch (error) {
    console.error("âŒ APIã‚¨ãƒ©ãƒ¼:", error);
    return NextResponse.json({ message: "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚", error: error.message }, { status: 500 });
  }
}
